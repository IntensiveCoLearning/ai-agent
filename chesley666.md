---
timezone: UTC+8
---

> 请在上边的 timezone 添加你的当地时区(UTC)，这会有助于你的打卡状态的自动化更新，如果没有添加，默认为北京时间 UTC+8 时区

# 你的名字

1. 自我介绍  
   web2 测试工程师转 web3，炒币老韭菜
2. 你认为你会完成本次残酷学习吗？  
   能
3. 你的联系方式（推荐 Telegram）  
   rorozn*OvQ*

## Notes

<!-- Content_START -->

### 2025.06.01

- **AGI 的核心构件**  
  | 模块 | 描述 | 当前进展 | AGI 所需能力 |
  | ----------------- | -------------- | --------------- | --------------- |
  | 感知 Perception | 多模态感知世界 | MLLMs 发展迅速 | 多模态融合、鲁棒、可解释 |
  | 推理 Reasoning | 思维、逻辑、计划 | CoT、ReAct、ToT | 因果推理、长链推理、跨域泛化 |
  | 记忆 Memory | 存储与回溯信息 | 短期（上下文）、长期（知识库） | 层级结构、自主更新、协作共享 |
  | 元认知 Metacognition | 自我意识、自我反思、自主学习 | 初步具备性格与角色意识 | 自演化、自我理解、社会互动能力 |

- **ReAct 的核心思想**  
  传统的语言模型主要专注于推理（如 Chain-of-Thought）或行动（如 WebGPT、SayCan），而 ReAct 将这两者有机结合，形成一个闭环：
  - 推理（Thoughts）：模型通过语言生成思维过程，帮助制定和更新行动计划。
  - 行动（Actions）：模型执行具体操作，如调用 API、查询数据库等，以获取外部信息。
  - 观察（Observations）：模型根据行动结果更新内部状态，形成新的推理基础。
  - 这种交替进行的“思 → 行 → 观”循环，使模型能够动态适应环境，处理复杂任务。
- **ReAct 的设计理念与 AGI 的核心能力契合**：
  - 推理能力：通过语言生成思维过程，实现复杂的逻辑推理。
  - 行动能力：能够执行具体操作，与外部环境交互。
  - 记忆与观察：根据行动结果更新内部状态，形成新的知识。
  - 元认知能力：通过自我反思和调整，优化行为策略。
  - 因此，ReAct 可视为构建通用智能体（AGI）的重要步骤。
- 参考：  
  项目主页：https://react-lm.github.io/  
  论文链接：https://arxiv.org/abs/2210.03629  
  代码仓库：https://github.com/ysymyth/ReAct

### 2025.06.02

- **推理**
  - [ReAct](https://arxiv.org/abs/2210.03629)
    - 核心思想： 大语言模型（LLM）能够交替生成“思维过程（reasoning traces）”和“任务动作（task-specific actions）”。 这种“思 → 行 → 观”的循环，使模型能够动态适应环境，处理复杂任务。
    - 推理过程（Reasoning Traces）：模型通过语言生成思维过程，帮助制定和更新行动计划。
    - 任务动作（Task-Specific Actions）：模型执行具体操作，如调用 API、查询数据库等，以获取外部信息。
    - 观察反馈（Observations）：模型根据行动结果更新内部状态，形成新的推理基础
  - [Tree of Thoughts](https://arxiv.org/abs/2305.10601)
    - 核心思想： 语言模型能够在推理过程中进行多路径探索、自我评估和回溯，从而提升问题解决能力
    - 思维树结构（Tree Structure）：将问题的解决过程表示为一棵树，每个节点代表一个思维步骤，模型可以在树上进行探索和选择。
    - 多路径探索（Multiple Reasoning Paths）：模型可以同时探索多个推理路径，避免陷入局部最优解。
    - 自我评估与回溯（Self-Evaluation and Backtracking）：模型能够评估当前路径的有效性，并在必要时回溯到之前的节点，重新选择路径
- **规划**
  - [LLM+PDDL](https://arxiv.org/abs/2304.11477)
    - 核心思想： LLM+P 框架结合了大语言模型的自然语言处理能力和经典规划器的高效搜索能力。该方法首先将自然语言描述转换为规划领域定义语言（PDDL），然后利用经典规划器生成解决方案，最后将解决方案翻译回自然语言。
    - 自然语言到 PDDL 的转换：将自然语言描述的规划问题转换为规划领域定义语言（PDDL）格式。
    - 利用经典规划器求解：使用经典规划器（如 FastDownward）在 PDDL 表示下高效地搜索最优或可行的解决方案。
    - 结果转换回自然语言：将规划器生成的解决方案翻译回自然语言，供用户理解和执行。
  - [LATS](https://arxiv.org/abs/2310.04406)
    - 核心思想： LATS（Language Agent Tree Search）框架通过整合蒙特卡洛树搜索（MCTS）、语言模型驱动的价值函数和自我反思机制，实现了推理、行动和规划的统一。
    - 蒙特卡洛树搜索（MCTS）：利用 MCTS 在决策树中进行探索，寻找最优的行动路径。
    - 语言模型驱动的价值函数：使用语言模型评估当前状态的价值，指导搜索过程。
    - 自我反思机制：模型在决策过程中进行自我评估和调整，提升决策质量。
    - 环境反馈整合：通过与外部环境的交互，获取反馈信息，进一步优化决策策略。
- **记忆**
  - [CoALA](https://arxiv.org/abs/2309.02427)
    - **核心思想**：CoALA（Cognitive Architectures for Language Agents）提出了一种认知架构，旨在为语言代理系统提供模块化的记忆组件、结构化的动作空间以及通用的决策过程，以实现更高效的推理、学习和决策能力。
    - **模块化记忆组件**：将记忆系统划分为多个模块，每个模块负责存储不同类型的信息，如短期记忆、长期记忆和外部知识库，以支持多样化的任务需求。
    - **结构化动作空间**：定义了与内部记忆和外部环境交互的动作空间，使代理能够通过结构化的方式访问和更新记忆内容。
    - **通用决策过程**：引入了一种通用的决策机制，使代理能够根据当前状态和目标，选择最合适的行动策略，从而实现灵活的行为控制。
  - [HippoRAG](https://arxiv.org/abs/2405.14831)
    - **核心思想**：HippoRAG（Neurobiologically Inspired Long-Term Memory for Large Language Models）受人类海马体索引理论的启发，提出了一种新的检索框架，旨在增强大语言模型对新知识的整合能力，避免灾难性遗忘。
    - **海马体索引机制**：模拟人类海马体在长期记忆形成中的作用，通过建立索引来快速访问相关记忆，从而提高信息检索的效率和准确性。
    - **知识图谱集成**：将知识图谱与语言模型相结合，利用结构化的知识表示来丰富模型的语义理解和推理能力。
    - **个性化 PageRank 算法**：采用个性化的 PageRank 算法对知识图谱进行排序，优先检索与当前任务最相关的信息，提升检索结果的质量。
    - 代码：https://github.com/OSU-NLP-Group/HippoRAG

### 2025.06.03

- 推理 [思维链](https://arxiv.org/abs/2201.11903)：改进提示方法
  - 核心思想：该研究提出了“思维链提示（Chain-of-Thought Prompting）”方法，通过在提示中加入一系列中间推理步骤，引导大语言模型（LLM）模拟人类的思维过程，从而显著提升其在复杂推理任务中的表现。
  - 思维链提示：在提示中提供包含中间推理步骤的示例，帮助模型学习如何逐步推理。
  - 实验验证：在算术、常识推理和符号推理等任务中，使用思维链提示的模型表现优于传统提示方法。例如，使用 8 个思维链示例提示 540B 参数的模型，在 GSM8K 数学题基准上取得了超过微调 GPT-3 的准确率。
- 规划 [TravelPlanner](https://arxiv.org/abs/2402.01622)：建立现实世界的基准测试
  - 该研究提出了 TravelPlanner 基准测试，旨在评估语言代理（Language Agents）在现实世界复杂规划任务中的能力，特别是在旅行规划场景中。
  - 丰富的测试环境：提供了一个包含近 400 万条数据记录的沙盒环境，以及 1,225 个精心策划的规划意图和参考计划。
  - 多维度评估：评估语言代理在处理多约束条件下的任务保持性、工具使用和信息检索等方面的能力。
  - 实验结果：即使是最先进的模型，如 GPT-4，在该基准测试中的成功率也仅为 0.6%，表明当前语言代理在复杂规划任务中仍面临挑战。
  - 推动能力提升：该基准测试促使研究者关注 AI Agent 在多约束条件下的任务执行能力，推动其在实际应用中的发展。

### 2025.06.04

请假

### 2025.06.05

请假

### 2025.06.06

- 多模态  
  多模态大语言模型（Multimodal Large Language Model，简称 MLLM）是一类能够同时处理和理解多种类型数据（如文本、图像、音频、视频等）的人工智能模型。它们在传统大语言模型（LLM）的基础上，融合了多模态信息，使得模型具备更强的感知、理解和生成能力

  - 核心原理：
    - 模态编码器：负责将原始的多模态信息（如图像、音频等）转换为模型可理解的特征表示。例如，图像可以通过卷积神经网络（CNN）提取视觉特征，音频可以通过循环神经网络（RNN）或 Transformer 等模型处理
    - 连接器：将不同模态的特征进一步融合，形成统一的特征向量，供后续的语言模型处理。关键在于如何有效地将不同模态的特征进行对齐和融合
    - 大语言模型（LLM）：作为“大脑”，综合处理融合后的多模态信息，进行理解和推理，最终生成自然语言输出。LLM 通常采用 Transformer 等先进的神经网络架构
  - [Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs](https://arxiv.org/abs/2401.06209)  
    当前多模态大语言模型（MLLMs）在视觉理解方面存在系统性不足，主要源于其视觉模块依赖于 CLIP 等对比学习模型，导致在视觉细节辨别上存在盲点

    - CLIP 盲点识别：研究发现 CLIP 存在“视觉盲点”，即对视觉上明显不同的图像产生相似的嵌入表示

    - MMVP 基准构建：基于上述盲点，构建了 Multimodal Visual Patterns（MMVP）基准，涵盖九种基本视觉模式，用于评估 MLLMs 在视觉理解方面的能力
    - 性能评估：在 MMVP 上测试了多种 MLLMs，包括 GPT-4V，发现它们在处理简单视觉问题时仍会产生错误答案和幻觉解释
    - 特征融合方法：提出了 Mixture of Features（MoF）方法，将视觉自监督学习的特征与 MLLMs 融合，显著提升了模型的视觉定位能力

  - [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks](https://arxiv.org/abs/2401.13649)
    - 任务设计：构建了一系列多样且复杂的网页任务，要求智能体处理图文输入，理解自然语言指令，并在网页上执行操作以完成用户定义的目标。
    - 模型评估：对多种基于 LLM 的自主智能体进行了广泛评估，包括多个多模态模型，发现文本代理在需要视觉信息的任务中表现不佳，而现有多模态代理也存在能力差距
    - 收集了 233 个任务的人类操作轨迹，作为性能上限参考，提供了约 89%的成功率

### 2025.06.07

### 2025.06.08

### 2025.06.09

### 2025.06.10

### 2025.06.11

### 2025.06.12

### 2025.06.13

### 2025.06.14

### 2025.06.15

### 2025.06.16

### 2025.06.17

### 2025.06.18

### 2025.06.19

### 2025.06.20

### 2025.06.21

<!-- Content_END -->
